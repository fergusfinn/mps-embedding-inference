Warming up...
Benchmarking for 60s with 1024 concurrent requests, max_tokens=512...

=== Generative Benchmark Results ===
Duration: 113.0s
Total requests: 1024
Total tokens generated: 524288
Throughput: 4640.4 tokens/sec
Avg tokens/request: 512.0

--- Per-request latency ---
  p50: 87.32s  p95: 112.41s  p99: 112.78s
--- Per-token latency ---
  p50: 170.5ms  p95: 219.5ms  p99: 220.3ms
  Decode rate (p50): 5.9 tok/s/request
