"""
Analyze nsys kernel traces to detect kernel overlap between gen and embed workloads.

Usage:
    python analyze_nsys.py <results_dir>

Expects nsys-rep files (auto-exported to sqlite):
    <results_dir>/step1_gen_profile.nsys-rep   (gen-only baseline)
    <results_dir>/step2_gen_profile.nsys-rep   (gen under MPS)
    <results_dir>/step2_embed_profile.nsys-rep (embed under MPS)
    <results_dir>/step3_gen_profile.nsys-rep   (gen time-sliced)
    <results_dir>/step3_embed_profile.nsys-rep (embed time-sliced)

Reads kernel data from the CUPTI_ACTIVITY_KIND_KERNEL table in each
profile's SQLite export (generated by nsys stats --export sqlite).
"""
import sys
import os
import sqlite3
import subprocess
import numpy as np


def ensure_sqlite(nsys_rep_path):
    """Convert .nsys-rep to .sqlite if not already done. Returns sqlite path."""
    sqlite_path = nsys_rep_path.replace(".nsys-rep", ".sqlite")
    if not os.path.exists(sqlite_path):
        # nsys stats auto-generates the sqlite when run
        subprocess.run(
            ["nsys", "stats", "--format", "csv", "--report", "cuda_gpu_kern_sum",
             nsys_rep_path],
            capture_output=True, timeout=120
        )
    if not os.path.exists(sqlite_path):
        # Direct export as fallback
        subprocess.run(
            ["nsys", "export", "--type", "sqlite", "--output", sqlite_path,
             nsys_rep_path],
            capture_output=True, timeout=120
        )
    return sqlite_path if os.path.exists(sqlite_path) else None


def read_kernels_from_sqlite(sqlite_path):
    """Read kernel events from an nsys SQLite export."""
    conn = sqlite3.connect(sqlite_path)
    cursor = conn.cursor()

    # Check if the kernel table exists
    cursor.execute(
        "SELECT name FROM sqlite_master WHERE type='table' AND name='CUPTI_ACTIVITY_KIND_KERNEL'"
    )
    if not cursor.fetchone():
        conn.close()
        return []

    cursor.execute('''
        SELECT k.start, k.end,
               k.gridX, k.gridY, k.gridZ,
               k.blockX, k.blockY, k.blockZ,
               k.registersPerThread,
               s.value
        FROM CUPTI_ACTIVITY_KIND_KERNEL k
        LEFT JOIN StringIds s ON k.demangledName = s.id
        ORDER BY k.start
    ''')

    kernels = []
    for row in cursor.fetchall():
        start, end, gx, gy, gz, bx, by, bz, regs, name = row
        duration = end - start
        if duration <= 0:
            continue
        kernels.append({
            "start": start,
            "end": end,
            "duration": duration,
            "blocks": gx * gy * gz,
            "threads_per_block": bx * by * bz,
            "registers": regs,
            "name": name or "",
        })

    conn.close()
    return kernels


def read_gpu_trace(profile_path):
    """Read kernel events from an nsys profile (nsys-rep or sqlite)."""
    if profile_path.endswith(".nsys-rep"):
        sqlite_path = ensure_sqlite(profile_path)
        if not sqlite_path:
            print(f"  WARNING: Could not generate sqlite from {profile_path}")
            return []
        return read_kernels_from_sqlite(sqlite_path)
    elif profile_path.endswith(".sqlite"):
        return read_kernels_from_sqlite(profile_path)
    else:
        return []


def compute_overlap(gen_kernels, embed_kernels):
    """Compute total overlap time between gen and embed kernel events.

    Uses a sweep-line algorithm: merge all start/end events, track how many
    gen and embed kernels are active, and accumulate time where both > 0.
    """
    if not gen_kernels or not embed_kernels:
        return 0, 0, 0

    events = []
    for k in gen_kernels:
        events.append((k["start"], 1, 0))   # gen start
        events.append((k["end"], -1, 0))     # gen end
    for k in embed_kernels:
        events.append((k["start"], 0, 1))    # embed start
        events.append((k["end"], 0, -1))     # embed end

    events.sort(key=lambda x: x[0])

    gen_active = 0
    embed_active = 0
    overlap_ns = 0
    prev_time = events[0][0]

    for time, gen_delta, embed_delta in events:
        if gen_active > 0 and embed_active > 0:
            overlap_ns += time - prev_time
        prev_time = time
        gen_active += gen_delta
        embed_active += embed_delta

    gen_total = sum(k["duration"] for k in gen_kernels)
    embed_total = sum(k["duration"] for k in embed_kernels)

    return overlap_ns, gen_total, embed_total


def kernel_duration_stats(kernels):
    """Compute duration statistics for a list of kernels."""
    if not kernels:
        return {"count": 0, "mean_us": 0, "median_us": 0, "p99_us": 0, "total_ms": 0}
    durations = np.array([k["duration"] for k in kernels], dtype=np.float64)
    return {
        "count": len(durations),
        "mean_us": np.mean(durations) / 1000,
        "median_us": np.median(durations) / 1000,
        "p99_us": np.percentile(durations, 99) / 1000,
        "total_ms": np.sum(durations) / 1e6,
    }


def theoretical_occupancy(kernels, num_sms=132):
    """Estimate theoretical SM occupancy from grid dimensions.

    Each block occupies one SM slot. If a kernel launches N blocks,
    it can occupy min(N, num_sms) SMs. This is a rough upper bound --
    actual occupancy depends on registers, shared memory, and warp limits.
    Default num_sms=132 for H100/H200 (Hopper). Use 128 for RTX 4090.
    """
    if not kernels:
        return {"mean_blocks": 0, "mean_sm_frac": 0}
    blocks = np.array([k["blocks"] for k in kernels], dtype=np.float64)
    sm_frac = np.minimum(blocks, num_sms) / num_sms
    return {
        "mean_blocks": np.mean(blocks),
        "mean_sm_frac": np.mean(sm_frac),
    }


def categorize_kernel(name):
    """Categorize a kernel by its function in the model pipeline."""
    name_lower = name.lower()
    if any(k in name_lower for k in ["moe", "expert", "topk", "gate", "routing", "permute"]):
        return "moe"
    if any(k in name_lower for k in ["attention", "attn", "flash", "fmha", "sdpa"]):
        return "attention"
    if any(k in name_lower for k in ["gemm", "cutlass", "cublas", "matmul", "linear", "sgemm", "hgemm"]):
        return "gemm"
    if any(k in name_lower for k in ["layernorm", "rmsnorm", "norm"]):
        return "norm"
    if any(k in name_lower for k in ["elementwise", "activation", "silu", "gelu", "relu", "add_"]):
        return "activation"
    if any(k in name_lower for k in ["copy", "memcpy", "memset", "transpose", "reshape", "cast"]):
        return "memory"
    return "other"


def kernel_category_breakdown(kernels):
    """Break down kernels by category and report time distribution."""
    categories = {}
    for k in kernels:
        cat = categorize_kernel(k["name"])
        if cat not in categories:
            categories[cat] = {"count": 0, "total_ns": 0}
        categories[cat]["count"] += 1
        categories[cat]["total_ns"] += k["duration"]

    total_ns = sum(c["total_ns"] for c in categories.values())
    result = {}
    for cat, data in sorted(categories.items(), key=lambda x: -x[1]["total_ns"]):
        result[cat] = {
            "count": data["count"],
            "total_ms": data["total_ns"] / 1e6,
            "pct": (data["total_ns"] / total_ns * 100) if total_ns > 0 else 0,
        }
    return result


def analyze_step(label, gen_profile, embed_profile=None):
    """Analyze one experimental step."""
    print(f"\n--- {label} ---")

    if not os.path.exists(gen_profile):
        print(f"  Gen profile not found: {gen_profile}")
        return None

    gen_kernels = read_gpu_trace(gen_profile)
    if not gen_kernels:
        print(f"  No gen kernels found in {gen_profile}")
        return None

    gen_stats = kernel_duration_stats(gen_kernels)
    gen_occ = theoretical_occupancy(gen_kernels)

    print(f"  Gen kernels: {gen_stats['count']}")
    print(f"  Gen kernel duration: mean={gen_stats['mean_us']:.1f}us  median={gen_stats['median_us']:.1f}us  p99={gen_stats['p99_us']:.1f}us")
    print(f"  Gen total kernel time: {gen_stats['total_ms']:.1f}ms")
    print(f"  Gen theoretical SM occupancy: {gen_occ['mean_sm_frac']*100:.1f}% (mean {gen_occ['mean_blocks']:.0f} blocks/kernel, 132 SMs)")

    # MoE kernel categorization
    gen_cats = kernel_category_breakdown(gen_kernels)
    if gen_cats:
        print(f"  Gen kernel breakdown:")
        for cat, data in gen_cats.items():
            print(f"    {cat:12s}: {data['count']:6d} kernels, {data['total_ms']:8.1f}ms ({data['pct']:5.1f}%)")

    if embed_profile and os.path.exists(embed_profile):
        embed_kernels = read_gpu_trace(embed_profile)
        if not embed_kernels:
            print(f"  No embed kernels found in {embed_profile}")
            return gen_stats

        embed_stats = kernel_duration_stats(embed_kernels)
        embed_occ = theoretical_occupancy(embed_kernels)

        print(f"  Embed kernels: {embed_stats['count']}")
        print(f"  Embed kernel duration: mean={embed_stats['mean_us']:.1f}us  median={embed_stats['median_us']:.1f}us  p99={embed_stats['p99_us']:.1f}us")
        print(f"  Embed total kernel time: {embed_stats['total_ms']:.1f}ms")
        print(f"  Embed theoretical SM occupancy: {embed_occ['mean_sm_frac']*100:.1f}% (mean {embed_occ['mean_blocks']:.0f} blocks/kernel)")

        overlap_ns, gen_total_ns, embed_total_ns = compute_overlap(gen_kernels, embed_kernels)
        overlap_ms = overlap_ns / 1e6
        overlap_pct_gen = (overlap_ns / gen_total_ns * 100) if gen_total_ns > 0 else 0
        overlap_pct_embed = (overlap_ns / embed_total_ns * 100) if embed_total_ns > 0 else 0

        print(f"  Kernel overlap: {overlap_ms:.1f}ms")
        print(f"  Overlap as % of gen kernel time: {overlap_pct_gen:.1f}%")
        print(f"  Overlap as % of embed kernel time: {overlap_pct_embed:.1f}%")

        if overlap_ns > 0:
            print(f"  ==> KERNELS ARE OVERLAPPING (MPS concurrent execution confirmed)")
        else:
            print(f"  ==> NO kernel overlap detected (serialized execution)")
    elif embed_profile:
        print(f"  Embed profile not found: {embed_profile}")

    return gen_stats


def main():
    if len(sys.argv) != 2:
        print(f"Usage: {sys.argv[0]} <results_dir>")
        sys.exit(1)

    results_dir = sys.argv[1]

    print("=== nsys Kernel Overlap Analysis ===")

    s1 = analyze_step(
        "Step 1: Gen only (baseline)",
        os.path.join(results_dir, "step1_gen_profile.nsys-rep"),
    )

    s2 = analyze_step(
        "Step 2: Co-located with MPS",
        os.path.join(results_dir, "step2_gen_profile.nsys-rep"),
        os.path.join(results_dir, "step2_embed_profile.nsys-rep"),
    )

    s3 = analyze_step(
        "Step 3: Co-located without MPS (time-sliced)",
        os.path.join(results_dir, "step3_gen_profile.nsys-rep"),
        os.path.join(results_dir, "step3_embed_profile.nsys-rep"),
    )

    # Cross-step comparison
    if s1 and s2 and s3:
        print("\n--- Cross-step comparison: Gen kernel duration ---")
        print(f"  {'':20s} {'Count':>8s}  {'Mean(us)':>10s}  {'Median(us)':>10s}  {'P99(us)':>10s}")
        print(f"  {'Step 1 (gen only)':20s} {s1['count']:>8d}  {s1['mean_us']:>10.1f}  {s1['median_us']:>10.1f}  {s1['p99_us']:>10.1f}")
        print(f"  {'Step 2 (MPS)':20s} {s2['count']:>8d}  {s2['mean_us']:>10.1f}  {s2['median_us']:>10.1f}  {s2['p99_us']:>10.1f}")
        print(f"  {'Step 3 (time-sliced)':20s} {s3['count']:>8d}  {s3['mean_us']:>10.1f}  {s3['median_us']:>10.1f}  {s3['p99_us']:>10.1f}")

        if s1['mean_us'] > 0:
            print(f"\n  Gen kernel slowdown vs baseline:")
            print(f"    MPS:         {(s2['mean_us']/s1['mean_us'] - 1)*100:+.1f}%")
            print(f"    Time-sliced: {(s3['mean_us']/s1['mean_us'] - 1)*100:+.1f}%")


if __name__ == "__main__":
    main()
