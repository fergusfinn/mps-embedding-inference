Warming up...
Benchmarking for 60s with 1024 concurrent requests, max_tokens=512...

=== Generative Benchmark Results ===
Duration: 113.0s
Total requests: 1024
Total tokens generated: 524288
Throughput: 4640.9 tokens/sec
Avg tokens/request: 512.0

--- Per-request latency ---
  p50: 87.22s  p95: 112.44s  p99: 112.80s
--- Per-token latency ---
  p50: 170.3ms  p95: 219.6ms  p99: 220.3ms
  Decode rate (p50): 5.9 tok/s/request
